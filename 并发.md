#### 并发

并发的概念
  : 并发是指单个处理器，多道程序运行，程序分别占用时间片，这些程序关系就是并发；

并行的概念
    : 并行是多个处理器，分别处理不同的程序，程序在同一实际同时运行；

二者区别

  * 处理器数量；一个指单个，一个指多个
  * 运行时间，并发是指程序开始到结束期间时间有重叠，但是程序不同时运行，并行是同时运行； 


#### 多线程

> 好吧，事实证明，存在某些类型
的程序，我们称之为多线程（multi-threaded）应用程序。每个线程（thread）都像在这个程
序中运行的独立代理程序，代表程序做事。但是这些线程访问内存，对于它们来说，每个
内存节点就像一个桃子。如果我们不协调线程之间的内存访问，程序将无法按预期工作。

> 为单个运行进程提供的新抽象：线程（thread）。经典观点是一个程序只有
一个执行点（一个程序计数器，用来存放要执行的指令），但多线程（multi-threaded）程序
会有多个执行点（`多个程序计数器，每个都用于取指令和执行`）。换一个角度来看，每个线
程类似于独立的进程，只有一点区别：`它们共享地址空间，从而能够访问相同的数据。`

#### 进程和线程区别

> 线程有一个程序计数器（PC），记录程序
从哪里获取指令。每个线程有自己的一组用于计算的寄存器。所以，如果有两个线程运行
在一个处理器上，从运行一个线程（T1）切换到另一个线程（T2）时，必定发生上下文切
换（context switch）。线程之间的上下文切换类似于进程间的上下文切换。对于进程，我们
将状态保存到进程控制块（Process Control Block，PCB）。现在，我们需要一个或多个线程
控制块（Thread Control Block，TCB），保存每个线程的状态。但是，与进程相比，线程之
间的上下文切换有一点主要区别：地址空间保持不变（即不需要切换当前使用的页表）。

> 在多线程的进程中，每个线程独立运行，当然可以调用各种例程来完成正在执
行的任何工作。不是地址空间中只有一个栈，而是每个线程都有一个栈



![image](https://github.com/shushuxie/OS/assets/54092341/c6fb1e06-f8a6-4c87-ac0c-a51908618322)



> 进程控制块(PCB, Process Control Block)是操作系统用来管理进程运行的数据结构。每个进程都在操作系统中有一个对应的PCB，因此PCB是进程存在的唯一标志。

当进程创建时，生成PCB。进程终止时，操作系统会回收它的PCB。PCB的主要内容如下：

调度和状态信息：调度进程和处理机使用情况
进程间通信信息：进程间通信相关的各种标识
存储管理信息：指向进程映像存储空间数据结构
进程所用资源：进程使用的系统资源，如打开文件等
有关数据结构连接信息：与PCB相关的进程队列

线程是进程的一部分，描述指令流执行状态，它是进程中指令执行流的最小单元，是CPU调度的基本单位。
进程是资源分配维度的概念：由一组相关资源构成，包括地址空间（代码段、数据段）、打开的文件等各种资源。
线程是处理机调度维度的概念：描述在进程资源环境中的指令流执行状态。

cpu调度以线程为单位进行分配，pid1-Thread1，pid1-Thread2，pid2-threa1；

```
PCB含有三大类信息： 
（1） 进程标识，哪个程序在执行，执行了几次（本进程的标识），产生者标识（父进程标识），用户标识 
（2） 处理机状态信息保存区，主要就是寄存器，保存进程的运行现场信息：

用户可见寄存器，程序使用的数据，地址
控制和状态寄存器，程序计数器pc，程序状态字PSW
栈指针，过程调用/系统调用/中断处理和返回时需要用到
（3） 进程控制信息

调度和状态信息，用于操作系统调度进程并占用处理机使用。运行状态？等待？进程当前的执行现状
进程间通信信息，各种标识、信号、信件等
进程本身的存储管理信息，即指向本进程映像存储空间的数据结构，内存信息，占了多少？要不要回收？
进程所用资源，打开使用的系统资源，如文件
有关数据结构连接信息，父进程，子进程，构成一个链，进程可以连接到一个进程队列，或链接到其他进程的PCB
```

#### 共享数据,调度不可控

```c
#include <stdio.h>
#include <assert.h>
 #include <pthread.h>
#include <unistd.h>

void *mythread(void *arg) {
     printf("%s\n", (char *) arg);
     return NULL;
     }

 int
 main(int argc, char *argv[]) {
    pthread_t p1, p2;
    int rc;
    printf("main: begin\n");
    rc = pthread_create(&p1, NULL, mythread, "A"); assert(rc == 0);
    rc = pthread_create(&p2, NULL, mythread, "B"); assert(rc == 0);
    // join waits for the threads to finish
    // join 方法保证主线程运行到这里会等待子线程运行结束，不然子线程
    // 还没运行整个进程就结束了，或者让主线程睡眠一会，给子线程运行时间；
//    rc = pthread_join(p1, NULL); assert(rc == 0);
//    rc = pthread_join(p2, NULL); assert(rc == 0);
    sleep(1);
    printf("main: end\n");
    return 0;
    }
```

```c
#include <stdio.h>
#include <pthread.h>

static volatile int counter = 0;

//
// mythread()
//
 // Simply adds 1 to counter repeatedly, in a loop
 // No, this is not how you would add 10,000,000 to
 // a counter, but it shows the problem nicely.
 //
 void *
 mythread(void *arg)
 {
 printf("%s: begin\n", (char *) arg);
 int i;
 for (i = 0; i < 1e7; i++) {
 counter = counter + 1;
 }
 printf("%s: done\n", (char *) arg);
 return NULL;
 }

 //
 // main()
 //
 // Just launches two threads (pthread_create)
 // and then waits for them (pthread_join)
 //
 int
 main(int argc, char *argv[])
 {
 pthread_t p1, p2;
 printf("main: begin (counter = %d)\n", counter);
 pthread_create(&p1, NULL, mythread, "A");
 pthread_create(&p2, NULL, mythread, "B");

 // join waits for the threads to finish
 pthread_join(p1, NULL);
 pthread_join(p2, NULL);
 printf("main: done with both (counter = %d)\n", counter);
 return 0;
 }
=============================================================
D:\clion\OS\cmake-build-debug\OS.exe
main: begin (counter = 0)
A: begin
B: begin
A: done
B: done
main: done with both (counter = 14030237)
```

![image](https://github.com/shushuxie/OS/assets/54092341/efe5a3bd-314f-43be-817f-f928d869ff04)

发生问题原因就是两个线程抢占同一个变量，线程1执行过程如果没有把更改后的值存回到响应地址空间，线程2取值仍是另原来的值，线程2完成了增加，线程1
拿到了时间片只是根据TCB内容重置了地址空间值，导致数据错误；我们更加希望`原子性`的操作，没有中间过程；

> 补充：关键并发术语
临界区、竞态条件、不确定性、互斥执行
这 4 个术语对于并发代码来说非常重要，我们认为有必要明确地指出。 请参阅 Dijkstra 的一些早期
著作[D65，D68]了解更多细节。
 临界区（critical section）是访问共享资源的一段代码，资源通常是一个变量或数据结构。
 竞态条件（race condition）出现在多个执行线程大致同时进入临界区时，它们都试图更新共享
的数据结构，导致了令人惊讶的（也许是不希望的）结果。
 不确定性（indeterminate）程序由一个或多个竞态条件组成，程序的输出因运行而异，具体取
决于哪些线程在何时运行。这导致结果不是确定的（deterministic），而我们通常期望计算机系统给出确
定的结果。
 为了避免这些问题，线程应该使用某种互斥（mutual exclusion）原语。这样做可以保证只有一
个线程进入临界区，从而避免出现竞态，并产生确定的程序输出。



#### 线程API

```c
#include <pthread.h> 
int 
pthread_create( pthread_t * thread, 
 const pthread_attr_t * attr, 
 void * (*start_routine)(void*), 
 void * arg); 
返回值：0代表成功，别的代表失败
参数依次是：pthread_t结构体，线程参数没有要求可以是NULL，线程运行的函数，运行函数的参数可以是NULL;

pthread_join(); 等待线程执行结束，然后主线程才会结束；
  
```



##### 锁API

```c
int pthread_mutex_lock(pthread_mutex_t *mutex); 
int pthread_mutex_unlock(pthread_mutex_t *mutex); 

所有锁必须正确初始化，以确保它们具有正确的值，并在锁和解锁被调用时
按照需要工作。
对于 POSIX 线程，有两种方法来初始化锁。一种方法是使用 PTHREAD_MUTEX_ 
INITIALIZER，如下所示：
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; 
这样做会将锁设置为默认值，从而使锁可用。初始化的动态方法（即在运行时）是调
用 pthread_mutex_init()，如下所示：
int rc = pthread_mutex_init(&lock, NULL); 
assert(rc == 0); // always check success! 
此函数的第一个参数是锁本身的地址，而第二个参数是一组可选属性

int pthread_mutex_trylock(pthread_mutex_t *mutex); 
int pthread_mutex_timedlock(pthread_mutex_t *mutex, 
 struct timespec *abs_timeout); 
这两个调用用于获取锁。如果锁已被占用，则 trylock 版本将失败。获取锁的 timedlock
定版本会在超时或获取锁后返回，以先发生者为准。因此，具有零超时的 timedlock 退化为
trylock 的情况。通常应避免使用这两种版本，但有些情况下，避免卡在（可能无限期的）
获取锁的函数中会很有用，我们将在以后的章节中看到
```

##### 条件变量API

```c
如果一个线程在等待另一个线程继
续执行某些操作，条件变量就很有用。希望以这种方式进行交互的程序使用两个主要函数：
int pthread_cond_wait(pthread_cond_t *cond, pthread_mutex_t *mutex); 
int pthread_cond_signal(pthread_cond_t *cond); 
要使用条件变量，必须另外有一个与此条件相关的锁。在调用上述任何一个函数时，
应该持有这个锁
```



#### 锁

#### 什么是锁

 `锁就是一个变量`，因此我们需要声明一个某种类型的锁变量（lock variable，如上面的 mutex），才能使用。这个锁变量（简称锁）保存了锁在某一时刻的状态。它要么是可用的 （available，或 unlocked，或 free），表示没有线程持有锁，要么是被占用的（acquired，或 locked， 或 held），表示有一个线程持有锁，正处于临界区。我们也可以保存其他的信息，比如持有 锁的线程，或请求获取锁的线程队列，但这些信息会隐藏起来，锁的使用者不会发现。  

```abap
lock_t mutex; // some globally-allocated lock 'mutex'
...
lock(&mutex);
balance = balance + 1;
unlock(&mutex); 

为临界区的代码加锁，使用完后释放锁；
```

 锁为程序员提供了最小程度的调度控制。我们把线程视为程序员创建的实体，但是被 操作系统调度，具体方式由操作系统选择。锁让程序员获得一些控制权。通过给临界区加 锁，可以保证临界区内只有一个线程活跃。锁将原本由操作系统调度的混乱状态变得更为 可控。  



#### Pthread锁

 POSIX 库将锁称为互斥量（mutex），因为它被用来提供线程之间的互斥。即当一个线 程在临界区，它能够阻止其他线程进入直到本线程离开临界区。  

 POSIX 的 lock 和 unlock 函数会传入一个变量，因为我们可能用不 同的锁来保护不同的变量。这样可以增加并发：不同于任何临界区都使用同一个大锁（粗 粒度的锁策略），通常大家会用不同的锁保护不同的数据和结构，从而允许更多的线程进入 临界区（细粒度的方案）。  

```c
 pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;

 Pthread_mutex_lock(&lock); // wrapper for pthread_mutex_lock()
 balance = balance + 1;
 Pthread_mutex_unlock(&lock); 
```

#### 锁的评价标准

- 1-互斥性  锁是否有效，能够阻止多个线程 进入临界区  
- 2-公平性  当锁可用时，是否每一个竞争线程有公平的机会抢到锁 ，有的锁会饿死；
- 3-性能（performance），具体来说，是使用锁之后增加的时间开销。有几种场景需 要考虑。一种是没有竞争的情况，即只有一个线程抢锁、释放锁的开支如何？另外一种是 一个 CPU 上多个线程竞争，性能如何？最后一种是多个 CPU、多个线程竞争时的性能。

#### 锁的实现方案

##### 方案1：控制中断

 最早提供的互斥解决方案之一，就是在临界区关闭中断。这个解决方案是为单处理器 系统开发的。  

 通过在进入临界区之前关闭中断（使用特 殊的硬件指令），可以保证临界区的代码不会被中断，从而原子地执行。结束之后，我们重 新打开中断（同样通过硬件指令），程序正常运行 。 

```c
 void lock() {
 DisableInterrupts();
 }
 void unlock() {
 EnableInterrupts();
 } 
```

###### 缺点

-  第一，一个贪婪的程序可能在它开始时就 调用 lock()，从而独占处理器。更糟的情况是，恶意程序调用 lock()后，一直死循环。后一 种情况，系统无法重新获得控制，只能重启系统。关闭中断对应用要求太多，不太适合作 为通用的同步解决方案。 
- 第二，这种方案不支持多处理器。如果多个线程运行在不同的 CPU 上，每个线程都试 图进入同一个临界区，关闭中断也没有作用。线程可以运行在其他处理器上，因此能够进 入临界区。多处理器已经很普遍了，我们的通用解决方案需要更好一些。
-  第三，关闭中断导致中断丢失，可能会导致严重的系统问题。假如磁盘设备完成了读 取请求，但 CPU 错失了这一事实，那么，操作系统如何知道去唤醒等待读取的进程？ 
- 最后一个不太重要的原因就是效率低。与正常指令执行相比，现代 CPU 对于关闭和打 开中断的代码执行得较慢。  

###### 

#####  方案2：测试并设置指令（原子交换）

需要硬件提供 test-and-set instruction  指令

```c
int TestAndSet(int *old_ptr, int new) {
 int old = *old_ptr; // fetch old value at old_ptr
 *old_ptr = new; // store 'new' into old_ptr
 return old; // return the old value
 } 

 该指令完成原子化操作，返回旧的值，并且把值更新为新的；
```

在没有该指令下我们实现锁的方案（锁就是一个变量，一个flag标识）

```c
typedef struct lock_t { int flag; } lock_t;
void init(lock_t *mutex) {
// 0 -> lock is available, 1 -> held
mutex->flag = 0;
}

// 加锁，当锁没有被占有设置为1，被占有就一直循环等待锁被释放；
void lock(lock_t *mutex) {
while (mutex->flag == 1) // TEST the flag
 ; // spin-wait (do nothing)
 mutex->flag = 1; // now SET it!
 }

 void unlock(lock_t *mutex) {
 mutex->flag = 0;
 }
图 28.1 第一次尝试：简单标志
```

![img](https://cdn.nlark.com/yuque/0/2023/png/38602243/1693557652038-03b94022-3bd2-4151-9e49-948bf01aa1cf.png)

这种方案的锁不一定能实现互斥（加锁会失败），如上图线程1调用加锁，但是没有设置flag值完成，程序中断被占用，线程2同样加锁操作但是把值设置完成，线程1再次占有执行权设置flag值（因为前面已经判断通过，执行后面的代码）；这样导致两个线程同时占有锁，`根本原因是锁的判断和设置必须是原子化操作，不然容易失效`；



```c
使用测试指令实现方案
typedef struct lock_t {
int flag;
} lock_t;

void init(lock_t *lock) {
// 0 indicates that lock is available, 1 that it is held
lock->flag = 0;
}
// 加锁。判断锁是否被占用和重新设置原子化操作；
 void lock(lock_t *lock) {
 while (TestAndSet(&lock->flag, 1) == 1)
 ; // spin-wait (do nothing)
 }

 void unlock(lock_t *lock) {
 lock->flag = 0;
 }
图 28.2 利用测试并设置的简单自旋锁
```

在加锁过程中，判断是否生效和设置新的值是原子化操作；当锁没有被占用,flage = 0 `TestAndSet(flag,1)` 判断为false，不会循环，但是会给flag设置新的值；线程可以执行临界区代码；

当锁被占用 flag = 1  `TestAndSet(flag,1)`判断为true，进入循环，知道前面线程释放锁才会执行临界区代码，并自己持有锁；



##### 自旋锁评价

1. 可以实现互斥
2. 没有公平性，因为一个线程如果不运行临界区代码结束不会释放锁，会导致别的线程饿死，一直没法执行
3. 单CPU开销较大，多CPU性能尚可；



##### 方案3: 比较并交换

 某些系统提供了另一个硬件原语，即比较并交换指令（SPARC 系统中是 compare-and-swap， x86 系统是 compare-and-exchange）。  

```c
1 int CompareAndSwap(int *ptr, int expected, int new) {
2 int actual = *ptr;
3 if (actual == expected)
4 *ptr = new;
5 return actual;
6 } 
```

锁的实现

```c
1 void lock(lock_t *lock) {
2 while (CompareAndSwap(&lock->flag, 0, 1) == 1)
3 ; // spin
4 }
```

加锁操作，当flag = 0，期望的是0然后设置新的值1；

#####  方案4: 链接的加载和条件式存储指令  

> 一些平台提供了实现临界区的一对指令。链接的加载 （load-linked）和条件式存储（store-conditional）可以用来配合使用，实现其他并发结构。



```c
int LoadLinked(int *ptr) {
		return *ptr;
}

int StoreConditional(int *ptr, int value) {
if (no one has updated *ptr since the LoadLinked to this address) {
	*ptr = value;
	return 1; // success!
} else {
		 return 0; // failed to update
	 }
}
图 28.4 链接的加载和条件式存储
```



> 链接的加载指令和典型加载指令类似，都是从内存中取出值存入一个寄存器。关键区 别来自条件式存储（store-conditional）指令，只有上一次加载的地址在期间都没有更新时， 才会成功，（同时更新刚才链接的加载的地址的值）。成功时，条件存储返回 1，并将 ptr 指 的值更新为 value。失败时，返回 0，并且不会更新值。



***实现的锁***

```c
void lock(lock_t *lock) 
{ 
while (1) 
	{ 
		while (LoadLinked(&lock->flag) == 1) 
		; // spin until it's zero 
  	// 当上一次链接加载地址没有更新，地址没有更新代表是同一个线程操做loadlink方法，没有
    // 别的线程竞争，可以加锁；不然上面的LoadLinked函数也不会通过；
		if (StoreConditional(&lock->flag, 1) == 1) 
		return; // if set-it-to-1 was a success: all done 
		        // otherwise: try it all over again 
	} 
} 
 
 void unlock(lock_t *lock) { 
 lock->flag = 0; 
 } 
图 28.5 使用 LL/SC 实现锁
```

> 注意条件式存储失败是如何发生的。一个线程调用 lock()，执行了链接的加载指令， 返回 0。在执行条件式存储之前，中断产生了，另一个线程进入 lock 的代码，也执行链接式 加载指令，同样返回 0。现在，两个线程都执行了链接式加载指令，将要执行条件存储。重 点是只有一个线程能够成功更新标志为 1，从而获得锁；第二个执行条件存储的线程会失败 228 第 28 章 锁  （因为另一个线程已经成功执行了条件更新），必须重新尝试获取锁。

##### 方案5: 获取并增加

> 硬件原语是获取并增加（fetch-and-add）指令，它能原子地返回特定地址的旧 值，并且让该值自增一。

```c
1 int FetchAndAdd(int *ptr) { 
2 int old = *ptr; 
3 *ptr = old + 1; 
4 return old; 
5 } 
1 typedef struct lock_t { 
2 int ticket; 
3 int turn; 
4 } lock_t; 
5 
6 void lock_init(lock_t *lock) { 
7 lock->ticket = 0; 
8 lock->turn = 0; 
9 } 
10 
11 void lock(lock_t *lock) { 
12 int myturn = FetchAndAdd(&lock->ticket); 
13 while (lock->turn != myturn) 
14 ; // spin 
15 } 
16 
17 void unlock(lock_t *lock) { 
18 FetchAndAdd(&lock->turn); 
19 } 
图 28.6 ticket 锁		
```



> 不是用一个值，这个解决方案使用了 ticket 和 turn 变量来构建锁。基本操作也很简单： 如果线程希望获取锁，首先对一个 ticket 值执行一个原子的获取并相加指令。这个值作为该 线程的“turn”（顺位，即 myturn）。根据全局共享的 lock->turn 变量，当某一个线程的（myturn  == turn）时，则轮到这个线程进入临界区。unlock 则是增加 turn，从而下一个等待线程可以 进入临界区。 
>
> 不同于之前的方法：本方法能够保证所有线程都能抢到锁。只要一个线程获得了 ticket 值，它最终会被调度。之前的方法则不会保证。比如基于测试并设置的方法，一个线程有 可能一直自旋，即使其他线程在获取和释放锁。

#### 自旋过多怎么解决

当有两个线程时，一个线程运行，另一个自旋等待，如果有N个线程，就会有N-1个线程等待浪费了太多的时间，因此仅仅有硬件支持并不足够，需要有操作系统的支持

##### 方案1: 适当放弃CPU

在要自旋的时候，放弃 CPU。

```c
 void init() { 
2 flag = 0; 
3 } 
4 
5 void lock() { 
6 while (TestAndSet(&flag, 1) == 1) 
7 yield(); // give up the CPU 
8 } 
9 
10 void unlock() { 
11 flag = 0; 
12 } 
图 28.7 测试并设置和让出实现的锁
```

> 在这种方法中，我们假定操作系统提供原语 yield()，线程可以调用它主动放弃 CPU， 让其他线程运行。线程可以处于 3 种状态之一（运行、就绪和阻塞）。yield()系统调用能够 让运行（running）态变为就绪（ready）态，从而允许其他线程运行。因此，让出线程本质 上取消调度（deschedules）了它自己。

但是公平性难以保证，会有的线程一直让出cpu最后饿死，无法进行调度；

##### 方案2: 使用队列，休眠代替自旋

```c
/**
简单起见，我们利用 Solaris 提供的支持，它提供了两个调用：park()能够让调用线程休
眠，unpark(threadID)则会唤醒 threadID 标识的线程。可以用这两个调用来实现锁，让调用
者在获取不到锁时睡眠，在锁可用时被唤醒。
**/
1 typedef struct lock_t { 
2 	int flag; 
3 	int guard; 
4 	queue_t *q; 
5 } lock_t; 
6 
7 void lock_init(lock_t *m) { 
8 	m->flag = 0; 
9 	m->guard = 0; 
10 	queue_init(m->q); 
11 } 
12 
13 void lock(lock_t *m) { 
14 		while (TestAndSet(&m->guard, 1) == 1) 
15 		; //acquire guard lock by spinning 
16 if (m->flag == 0) { 
17 		m->flag = 1; // lock is acquired 
18 		m->guard = 0; 
19 } else { 
20 		queue_add(m->q, gettid()); 
21 		m->guard = 0; 
22 		park(); 
23 	} 
24 } 
25 
26 void unlock(lock_t *m) { 
27 		while (TestAndSet(&m->guard, 1) == 1) 
28 		; //acquire guard lock by spinning 
29 if (queue_empty(m->q)) 
30 		m->flag = 0; // let go of lock; no one wants it 
31 else 
32 		unpark(queue_remove(m->q)); // hold lock (for next thread!) 
  
33 m->guard = 0; 
34 } 
图 28.8 使用队列，测试并设置、让出和唤醒的锁
```



#### 两阶段锁

> 两阶段锁（two-phase lock）。两阶段锁意识到 自旋可能很有用，尤其是在很快就要释放锁的场景。因此，两阶段锁的第一阶段会先自旋 一段时间，希望它可以获取锁。 但是，如果第一个自旋阶段没有获得锁，第二阶段调用者会睡眠，直到锁可用。



#### 基于锁的并发数据结构

hasnmap线程安全

链表，并发链表

并发队列

并发散列链表

并发计数器

#### 条件变量

线程之间的激活需要依赖别的线程条件变化；

 线程可以使用条件变量（condition variable），来等待一个条件变成真。条件变量是一个 显式队列，当某些执行状态（即条件，condition）不满足时，线程可以把自己加入队列，等 待（waiting）该条件。另外某个线程，当它改变了上述状态时，就可以唤醒一个或者多个 等待线程（通过在该条件上发信号），让它们继续执行。  

 条件变量有两种相关操作：wait()和 signal()。线程要睡 眠的时候，调用 wait()。当线程想唤醒等待在某个条件变量上的睡眠线程时，调用 signal()。  

```c
pthread_cond_wait(pthread_cond_t *c, pthread_mutex_t *m);
pthread_cond_signal(pthread_cond_t *c); 
```



```c
pthread_cond_wait(pthread_cond_t *c, pthread_mutex_t *m);
pthread_cond_signal(pthread_cond_t *c);
int done = 0;
pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t c = PTHREAD_COND_INITIALIZER;

// 线程退出，标识设为1 ，唤醒主线程
void thr_exit() {
Pthread_mutex_lock(&m);
done = 1;
Pthread_cond_signal(&c);
Pthread_mutex_unlock(&m);
 }

 void *child(void *arg) {
 printf("child\n");
 // 执行完代码退出
 thr_exit();
 return NULL;
 }

// join方法，子线程没有执行完就执行wait，睡眠；
 void thr_join() {
 Pthread_mutex_lock(&m);
 while (done == 0)
 Pthread_cond_wait(&c, &m);
 Pthread_mutex_unlock(&m);
 }

 int main(int argc, char *argv[]) {
 printf("parent: begin\n");
 pthread_t p;
 Pthread_create(&p, NULL, child, NULL);
 thr_join();
 printf("parent: end\n");
 return 0;
 }
 父线程等待子线程：使用条件变量
```



 wait()调用有一个参数，它是互斥 量。它假定在 wait()调用时，这个互斥量是已上锁状态。 `wait()的职责是释放锁，并让调用 线程休眠（原子地）`。当线程被唤醒时（在另外某个线程发信号给它后），它必须重新获取 锁，再返回调用者。这样复杂的步骤也是为了避免在线程陷入休眠时，产生一些竞态条件。 



- 第一种情况是父线程创建出子线程，但自己继续运行（假设只 有一个处理器），然后马上调用 thr_join()等待子线程。在这种情况下，它会先获取锁，检查 子进程是否完成（还没有完成），然后调用 wait()，让自己休眠。子线程最终得以运行，打 印出“child”，并调用 thr_exit()函数唤醒父进程，这段代码会在获得锁后设置状态变量 done， 然后向父线程发信号唤醒它。最后，父线程会运行（从 wait()调用返回并持有锁），释放锁， 打印出“parent:end”。
- 第二种情况是，子线程在创建后，立刻运行，设置变量 done 为 1，调用 signal 函数唤 醒其他线程（这里没有其他线程），然后结束。父线程运行后，调用 thr_join()时，发现 done 已经是 1 了，就直接返回。



##### 真的需要flag变量吗？

```c
void thr_exit() {
	Pthread_mutex_lock(&m);
	Pthread_cond_signal(&c);
	Pthread_mutex_unlock(&m);
}
void thr_join() {
	Pthread_mutex_lock(&m);
	Pthread_cond_wait(&c, &m);
 	Pthread_mutex_unlock(&m);
 } 
```

加入线程创建后立刻调用了exit方法，Pthread_cond_signal 会唤醒主线程，但此时主线程没有睡眠因此没有线程被唤醒，后面调用join方法运行了线程睡眠，但是不会再有线程取唤醒，会一直睡下去；flag保证触发这两个方法的关键条件；

##### 真的需要操作加锁吗？

```c
 void thr_exit() {
 	done = 1;
 	Pthread_cond_signal(&c);
 }

 void thr_join() {
 	if (done == 0)
 		Pthread_cond_wait(&c);
 } 
```

不加锁会产生竞态条件； 如果父进程调用 thr_join()，然后检查完 done 的值为 0，然后试图睡眠。但在调用 wait 进入睡眠之前，父进程被中断。子线程修改变 量 done 为 1，发出信号，同样没有等待线程。父线程再次运行时，就会长眠不醒  

```
使用信号量要加锁
```



#####  生产者/消费者（有界缓冲区）问题  

```c
int buffer[MAX];
int fill = 0;
int use = 0;
int count = 0;

void put(int value) {
	buffer[fill] = value;
	fill = (fill + 1) % MAX;
	count++;
 }

 int get() {
 int tmp = buffer[use];
 use = (use + 1) % MAX;
 count--;
 return tmp;
 }
图 30.9 最终的 put()和 get()方法


cond_t empty, fill;
mutex_t mutex;

void *producer(void *arg) {
int i;
for (i = 0; i < loops; i++) {
	Pthread_mutex_lock(&mutex);           // p1
	while (count == MAX)				  // p2
	 Pthread_cond_wait(&empty, &mutex);   // p3
	 put(i); 							  // p4
	 Pthread_cond_signal(&fill); 		  // p5
	 Pthread_mutex_unlock(&mutex);		  // p6
 }
 }

 void *consumer(void *arg) {
 int i;
 for (i = 0; i < loops; i++) {
 Pthread_mutex_lock(&mutex); 		// c1
 while (count == 0) 				// c2
 Pthread_cond_wait(&fill, &mutex);  // c3
 int tmp = get(); 					// c4
 Pthread_cond_signal(&empty); 		// c5
 Pthread_mutex_unlock(&mutex);		// c6
 printf("%d\n", tmp);
 }
 }
图 30.10 最终有效方案
```

- 需要解决问题是判断条件使用`while`每次调用之前会检查条件；
- 使用多个唤醒条件，以免消费者唤醒消费者，生产者唤醒生产者 发生错误；

##### 覆盖条件

需要唤醒的时候全部唤醒，不使用条件判断是否满足；

 因为它能覆盖 所有需要唤醒线程的场景（保守策略）。成本如上所述，就是太多线程被唤醒。  



#### 线程状态

- 就绪	可以运行，等待调度程序分配CPU
- 运行 占用CPU执行程序
- 阻塞 等待某种情况完成（例如IO操作），然后进入就绪态运行
- 等待，wait 等待，不运行需要唤醒才能进入就绪，运行
- 睡眠  不运行，睡眠时间结束进入就绪运行；

![img](https://cdn.nlark.com/yuque/0/2023/png/38602243/1693909186140-db4f35ff-7bc9-469d-a895-a0e5f2e18558.png)



#### 信号量

##### 信号量定义📶

> 信号量是有一个整数值的对象，可以用两个函数来操作它。在 POSIX 标准中，是 sem_wait()和 sem_post()①。因为信号量的初始值能够决定其行为，所以首先要初始化信号量， 才能调用其他函数与之交互，

```c
#include <semaphore.h> 
 sem_t s; 
 sem_init(&s, 0, 1); 
图 31.1 初始化信号量
  
第三个参数将它的值初始化为 1。sem_init()的第二个
参数，在我们看到的所有例子中都设置为 0，表示信号量是在同一进程的多个线程共享的。
读者可以参考手册，了解信号量的其他用法（即如何用于跨不同进程的同步访问），这要求
第二个参数用不同的值。
信号量初始化之后，我们可以调用 sem_wait()或 sem_post()与之交互。
```

```c
// wait方法将参数值加一 
int sem_wait(sem_t *s) { 
 decrement the value of semaphore s by one 
 wait if value of semaphore s is negative 
 } 
 
// post方法参数减一
 int sem_post(sem_t *s) { 
 increment the value of semaphore s by one 
 if there are one or more threads waiting, wake one 
 } 
图 31.2 信号量：Wait 和 Post 的定义
  
首先，sem_wait()要么立刻返回（调用 sem_wait()
时，信号量的值大于等于 1），要么会让调用线程挂起，直到之后的一个 post 操作。当然，
也可能多个调用线程都调用 sem_wait()，因此都在队列中等待被唤醒。
其次，sem_post()并没有等待某些条件满足。它直接增加信号量的值，如果有等待线程，
唤醒其中一个。
最后，当信号量的值为负数时，这个值就是等待线程的个数[D68b]。虽然这个值通常不
会暴露给信号量的使用者，
```

* wait方法会让调用的线程挂起，如果此时的信号量是负数；

##### 二值信号量（锁）-- 可以作为锁使用；

```c
 sem_t m; 
// 此时x的值应该为1，保证锁正常运行
 sem_init(&m, 0, X); // initialize semaphore to X; what should X be? 
 
 sem_wait(&m); 
 // critical section here 
 sem_post(&m); 
图 31.3 二值信号量（就是锁）
```

##### 信号量作为条件变量

信号量也可以用在一个线程暂停执行，等待某一条件成立的场景。

```c
 sem_t s; 

void *
child(void *arg) { 
printf("child\n"); 
sem_post(&s); // signal here: child is done 
return NULL; 
} 

 int 
 main(int argc, char *argv[]) { 
 // 此时的信号量X应该设置为0  
 sem_init(&s, 0, X); // what should X be? 
 printf("parent: begin\n"); 
 pthread_t c; 
 Pthread_create(c, NULL, child, NULL); 
 sem_wait(&s); // wait here for child 
 printf("parent: end\n"); 
 return 0; 
 } 
图 31.4 父线程等待子线程
```



##### 生产者/消费者（临界缓冲区）问题

```c
1 sem_t empty; 
2 sem_t full; 
3 sem_t mutex; 
4 
5 void *producer(void *arg) { 
6 int i; 
7 for (i = 0; i < loops; i++) { 
8 sem_wait(&empty); // line p1 
9 sem_wait(&mutex); // line p1.5 (MOVED MUTEX HERE...) 
10 put(i); // line p2 
11 sem_post(&mutex); // line p2.5 (... AND HERE) 
12 sem_post(&full); // line p3 
13 } 
14 } 
15 
16 void *consumer(void *arg) { 
17 int i; 
18 for (i = 0; i < loops; i++) { 
19 		sem_wait(&full); // line c1 
20 		sem_wait(&mutex); // line c1.5 (MOVED MUTEX HERE...) 
21 		int tmp = get(); // line c2 
22 		sem_post(&mutex); // line c2.5 (... AND HERE) 
23 		sem_post(&empty); // line c3 
24 		printf("%d\n", tmp); 
25 	} 
26 } 
27 
28 int main(int argc, char *argv[]) { 
29 // ... 
30 sem_init(&empty, 0, MAX); // MAX buffers are empty to begin with... 
31 sem_init(&full, 0, 0); // ... and 0 are full 
32 sem_init(&mutex, 0, 1); // mutex=1 because it is a lock 
33 // ... 
34 } 
图 31.8 增加互斥量（正确的）
```



##### 读写锁的实现

```c
typedef struct _rwlock_t { 
sem_t lock; // binary semaphore (basic lock) 
sem_t writelock; // used to allow ONE writer or MANY readers 
int readers; // count of readers reading in critical section 
} rwlock_t; 

void rwlock_init(rwlock_t *rw) { 
rw->readers = 0; 
sem_init(&rw->lock, 0, 1); 
 sem_init(&rw->writelock, 0, 1); 
 } 
 
 void rwlock_acquire_readlock(rwlock_t *rw) { 
 sem_wait(&rw->lock); 
 rw->readers++; 
 if (rw->readers == 1) 
 sem_wait(&rw->writelock); // first reader acquires writelock 
 sem_post(&rw->lock); 
 } 
 
 void rwlock_release_readlock(rwlock_t *rw) { 
 sem_wait(&rw->lock); 
 rw->readers--; 
 if (rw->readers == 0) 
 sem_post(&rw->writelock); // last reader releases writelock 
 sem_post(&rw->lock); 
 } 
 
 void rwlock_acquire_writelock(rwlock_t *rw) { 
 sem_wait(&rw->writelock); 
 } 
 
 void rwlock_release_writelock(rwlock_t *rw) { 
 sem_post(&rw->writelock); 
 } 
图 31.9 一个简单的读者-写者锁
```

> 获取和释放操作更加吸引人。获取读锁时，读者首先要获取 lock，然后增加 reader 变量，追踪目前有多少个读者在访问该数据结构。重要的步骤然后在 rwlock_acquire_readlock() 内发生，当第一个读者获取该锁时。在这种情况下，读者也会获取写锁，即在 writelock 信号 量上调用 sem_wait()，最后调用 sem_post()释放 lock。 一旦一个读者获得了读锁，其他的读者也可以获取这个读锁。但是，想要获取写锁的 线程，就必须等到所有的读者都结束。最后一个退出的写者在“writelock”信号量上调用 31.6 哲学家就餐问题 273  sem_post()，从而让等待的写者能够获取该锁



##### 如何实现信号量

```
底层的同步原语（锁和条件变量），来实现自己的信号量
```



```c
typedef struct _Zem_t { 
int value; 
pthread_cond_t cond; 
pthread_mutex_t lock; 
} Zem_t; 

// only one thread can call this 
void Zem_init(Zem_t *s, int value) { 
		 s->value = value; 
		 Cond_init(&s->cond); 
 		 Mutex_init(&s->lock); 
 } 
 
 void Zem_wait(Zem_t *s) { 
 		Mutex_lock(&s->lock); 
 		while (s->value <= 0) 
		 Cond_wait(&s->cond, &s->lock); 
		 s->value--; 
 		Mutex_unlock(&s->lock); 
 } 
 
 void Zem_post(Zem_t *s) { 

 	Mutex_lock(&s->lock); 
	s->value++; 
 	Cond_signal(&s->cond); 
 	Mutex_unlock(&s->lock); 
 } 
图 31.12 用锁和条件变量实现 Zemahpore 
```



实现信号量就是实现对应的方法 init，wait，post；

结构包含三部分 value标识，cond条件变量，lock互斥锁

init方法是初始化很简单，给所有量一个初始化值，方便后续使用

wait方法用锁包围实现原子化操作，为负数时就睡眠调用线程，否则减value--

post方法也用锁实现原子化操作，vale++，并唤醒睡眠线程；

