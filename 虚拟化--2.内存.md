#### 抽象地址空间

虚拟地址的一大作用就是让进程觉得自己独占了整个磁盘空间，其实仅仅是系统让你看到的假象。

早期的进程是单个的占用整个空间，后面改为了多个，可以运行多任务，就需要实现内存的保护，隔离；

##### 为什么要有虚拟内存

​	还是为了方便使用，如果只运行一个程序那么不需要；如果内存加载一个程序，然后放回磁盘加载另一个也可以，但是太慢了；保证多个用户，多个程序运行，又不互相影响，只能统一管理内存；

#### 插叙：内存操作API

```c
申请内存和释放操作
    malloc
    free()
    realloc()
    
    gdb，valgrind
    调试工具和valgrind内存检测工具；
```

#### 机制：地址转换

> 我们利用了一种通用技术，有时被称为`基于硬件`的地址转换（hardware-based address translation），简称为地址转换（address translation）。它可以看成是受限直接执行这种一般方 法的补充。利用地址转换，硬件对`每次内存访问进行处理`（即指令获取、数据读取或写 入），将指令中的虚拟（virtual）地址转换为数据实际存储的物理（physical）地址。因此， 在`每次内存引用时，硬件都会进行地址转换`，将应用程序的内存引用重定位到内存中实际 的位置。

> 仅仅依靠硬件不足以实现虚拟内存，因为它只是提供了底层机制来提高效率。 操作系统必须在关键的位置介入，设置好硬件，以便完成正确的地址转换。

> 所有这些工作都是为了创造一种美丽的假象：每个程序都拥有私有的内存，那 里存放着它自己的代码和数据。虚拟现实的背后是丑陋的物理事实：`许多程序其实是在同 一时间共享着内存`，就像 CPU（或多个 CPU）在不同的程序间切换运行。



##### 动态重定位

每个 CPU 需要两个硬件寄存器：基址（base）寄存器和界限（bound）寄存 器，有时称为限制（limit）寄存器。这组基址和界限寄存器，让我们能够将地址空间放在物 理内存的任何位置，同时又能确保进程只能访问自己的地址空间

`physical address = virtual address + base`



base提供了偏移量，bound用来检查内存安全

context switch的时候也会进行这种切换



硬件支持

* 模式内核，用户转换
* MMU处理地址计算

#### 内存分段

##### 为什么要分段

更好的利用内存，减少内部碎片浪费；分段之后可以分开存储每个段

##### 确定地址段的方式

1. 使用标识符

![img](https://cdn.nlark.com/yuque/0/2023/png/38602243/1692233132590-8c642289-bca0-4cec-ab8a-283fbd7a9b72.png)

1. 产生地址的方式



硬件还有其他方法来决定特定地址在哪个段。在隐式（implicit）方式中，硬件通过地 址产生的方式来确定段。例如，如果地址由程序计数器产生（即它是指令获取），那么地址 在代码段。如果基于栈或基址指针，它一定在栈段。其他地址则在堆段。



##### 支持共享

分段之后可以，让一些特定的段共享，例如代码段，但是必须要有硬件的支持，把响应的段标记为只读，进行保护才行；



##### 总结

 分段解决了一些问题，帮助我们实现了更高效的虚拟内存。不只是动态重定位，通过 避免地址空间的逻辑段之间的大量潜在的内存浪费，分段能更好地支持稀疏地址空间。它 还很快，因为分段要求的算法很容易，很适合硬件完成，地址转换的开销极小。分段还有 一个附加的好处：代码共享。如果代码放在独立的段中，这样的段就可能被多个运行的程 序共享。 但我们已经知道，在内存中分配不同大小的段会导致一些问题，我们希望克服。首先， 是我们上面讨论的外部碎片。由于段的大小不同，空闲内存被割裂成各种奇怪的大小，因 此满足内存分配请求可能会很难。用  



#### 空闲地址空间管理



##### 底层机制

* 分割与合并 	申请空间会分割给你，free会把相邻空闲空间进行合并
* ![image.png](https://cdn.nlark.com/yuque/0/2023/png/38602243/1692282694380-dd4e8f2a-1a1a-40c1-a833-5c22db6e2908.png)

* malloc分配空间，不是单纯的空间，还会分配一部分给一个头部，用来记录一些信息

  空间大小，magic用来安全性校验

  ##### 空间分配机制

  * 最优匹配  最优匹配（best fit）策略非常简单：首先遍历整个空闲列表，找到和请求大小一样或更 大的空闲块，然后返回这组候选者中最小的一块。这就是所谓的最优匹配（也可以称为最 小匹配）。只需要遍历一次空闲列表，就足以找到正确的块并返回。 最优匹配背后的想法很简单：选择最接它用户请求大小的块，从而尽量避免空间浪费。 然而，这有代价。简单的实现在遍历查找正确的空闲块时，要付出较高的性能代价。
  *  最差匹配  最差匹配（worst fit）方法与最优匹配相反，它尝试找最大的空闲块，分割并满足用户 需求后，将剩余的块（很大）加入空闲列表。最差匹配尝试在空闲列表中保留较大的块， 而不是向最优匹配那样可能剩下很多难以利用的小块。但是，最差匹配同样需要遍历整个 空闲列表。更糟糕的是，大多数研究表明它的表现非常差，导致过量的碎片，同时还有很 高的开销。 
  * 首次匹配  首次匹配（first fit）策略就是找到第一个足够大的块，将请求的空间返回给用户。同样， 剩余的空闲空间留给后续请求。 首次匹配有速度优势（不需要遍历所有空闲块），但有时会让空闲列表开头的部分有很 多小块。因此，分配程序如何管理空闲列表的顺序就变得很重要。一种方式是基于地址排 序（address-based ordering）。通过保持空闲块按内存地址有序，合并操作会很容易，从而减 少了内存碎片。
  *  下次匹配  不同于首次匹配每次都从列表的开始查找，下次匹配（next fit）算法多维护一个指针， 指向上一次查找结束的位置。其想法是将对空闲空间的查找操作扩散到整个列表中去，避 免对列表开头频繁的分割。这种策略的性能与首次匹配很接它，同样避免了遍历查找。
